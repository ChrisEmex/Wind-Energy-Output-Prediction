{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f86e8f-c6a8-48ac-a06b-e1ed37868b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c00adf0c-0c2a-430f-afd2-a53ba8374d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(filepath):\n",
    "    loc1 = pd.read_csv(filepath)\n",
    "    loc1['Time'] = pd.to_datetime(loc1['Time'])\n",
    "    loc1['Year'] = loc1['Time'].dt.year\n",
    "    loc1['Month'] = loc1['Time'].dt.month\n",
    "    features = ['Year', 'Month', 'temperature_2m', 'relativehumidity_2m', \n",
    "                'dewpoint_2m', 'windspeed_10m', 'windspeed_100m', \n",
    "                'winddirection_10m', 'winddirection_100m', 'windgusts_10m']\n",
    "    X = loc1[features]\n",
    "    y = loc1['Power']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b6d8c9-593e-4376-9d2e-9b277ebc8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for RandomizedSearchCV\n",
    "def get_param_grid():\n",
    "    return {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [5, 10, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdab83b0-be65-4207-89d3-3f5693036dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Adjusted R²\n",
    "def adjusted_r2(r2, n, p):\n",
    "    return 1 - (1 - r2) * (n - 1) / (n - p - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb4dbac-e637-48c2-8e93-fe78731a4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Random Forest model\n",
    "def train_and_evaluate_rf(X, y):\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=40)\n",
    "    \n",
    "    # Perform Randomized Search with Cross-Validation\n",
    "    param_grid = get_param_grid()\n",
    "    model = RandomForestRegressor(random_state=40)\n",
    "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, \n",
    "                                       n_iter=min(10, len(param_grid['n_estimators']) * len(param_grid['max_depth']) *\n",
    "                                                  len(param_grid['min_samples_split']) * len(param_grid['min_samples_leaf'])), \n",
    "                                       cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1, random_state=40)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best parameters and model\n",
    "    best_model = random_search.best_estimator_\n",
    "    print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    predictions = best_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    adj_r2 = adjusted_r2(r2, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    print(f'\\nRandom Forest Model Evaluation:')\n",
    "    print(f'Mean Squared Error (MSE): {mse}')\n",
    "    print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "    print(f'Mean Absolute Error (MAE): {mae}')\n",
    "    print(f'R² Score: {r2}')\n",
    "    print(f'Adjusted R² Score: {adj_r2}')\n",
    "\n",
    "    # Cross-validation scores on the best model\n",
    "    cv_results_mse = cross_val_score(best_model, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_cv = -cv_results_mse.mean()\n",
    "    rmse_cv = np.sqrt(mse_cv)\n",
    "    cv_results_mae = cross_val_score(best_model, X_scaled, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "    mae_cv = -cv_results_mae.mean()\n",
    "    cv_results_r2 = cross_val_score(best_model, X_scaled, y, cv=5, scoring='r2')\n",
    "    r2_cv = cv_results_r2.mean()\n",
    "    adj_r2_cv = adjusted_r2(r2_cv, X_scaled.shape[0], X_scaled.shape[1])\n",
    "\n",
    "    print(\"\\nCross-validation results:\")\n",
    "    print(f'Mean Cross-Validation MSE: {mse_cv}')\n",
    "    print(f'Mean Cross-Validation RMSE: {rmse_cv}')\n",
    "    print(f'Mean Cross-Validation MAE: {mae_cv}')\n",
    "    print(f'Mean Cross-Validation R²: {r2_cv}')\n",
    "    print(f'Mean Cross-Validation Adjusted R²: {adj_r2_cv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c53f256-368f-4961-81dd-b70afde68712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select most correlated features\n",
    "def get_most_correlated_features(X, y, threshold=0.5):\n",
    "    data_combined = pd.concat([X, y], axis=1)\n",
    "    corr_matrix = data_combined.corr()\n",
    "    target_corr = corr_matrix['Power'].drop('Power')\n",
    "    \n",
    "    # Select features above the correlation threshold\n",
    "    most_correlated_features = target_corr[abs(target_corr) > threshold].index.tolist()\n",
    "    print(f\"Most correlated features: {most_correlated_features}\")\n",
    "    \n",
    "    return most_correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6536bfd8-9582-4fff-bcd7-63cef5d5641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters found:  {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n",
      "\n",
      "Random Forest Model Evaluation:\n",
      "Mean Squared Error (MSE): 0.01975885172667169\n",
      "Root Mean Squared Error (RMSE): 0.14056618272782287\n",
      "Mean Absolute Error (MAE): 0.10439040205479452\n",
      "R² Score: 0.7608692213239359\n",
      "Adjusted R² Score: 0.7605958977684711\n",
      "\n",
      "Cross-validation results:\n",
      "Mean Cross-Validation MSE: 0.02942923971780621\n",
      "Mean Cross-Validation RMSE: 0.17154952555401082\n",
      "Mean Cross-Validation MAE: 0.13200177442922376\n",
      "Mean Cross-Validation R²: 0.6451660719585204\n",
      "Mean Cross-Validation Adjusted R²: 0.6450850392955134\n",
      "Most correlated features: ['windspeed_10m', 'windspeed_100m', 'windgusts_10m']\n",
      "\n",
      "Evaluating model on the most correlated features...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters found:  {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 5}\n",
      "\n",
      "Random Forest Model Evaluation:\n",
      "Mean Squared Error (MSE): 0.027073058772018394\n",
      "Root Mean Squared Error (RMSE): 0.16453892783173954\n",
      "Mean Absolute Error (MAE): 0.12603451986376646\n",
      "R² Score: 0.6723492986914513\n",
      "Adjusted R² Score: 0.6722370382867088\n",
      "\n",
      "Cross-validation results:\n",
      "Mean Cross-Validation MSE: 0.027790099228029684\n",
      "Mean Cross-Validation RMSE: 0.16670362691924157\n",
      "Mean Cross-Validation MAE: 0.12796341674998352\n",
      "Mean Cross-Validation R²: 0.6653239522584016\n",
      "Mean Cross-Validation Adjusted R²: 0.6653010271478155\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = 'Location1.csv'\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    X, y = load_and_preprocess_data(filepath)\n",
    "    \n",
    "    # Train and evaluate the model on all features\n",
    "    train_and_evaluate_rf(X, y)\n",
    "    \n",
    "    # Find most correlated features\n",
    "    most_correlated_features = get_most_correlated_features(X, y, threshold=0.5)\n",
    "    \n",
    "    # Train and evaluate the model on the most correlated features\n",
    "    print(\"\\nEvaluating model on the most correlated features...\")\n",
    "    X_most_corr = X[most_correlated_features]\n",
    "    train_and_evaluate_rf(X_most_corr, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860ff7a-4288-4599-8b3c-02debc988300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7917deb1-212b-439d-bd30-393ed02e96e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
