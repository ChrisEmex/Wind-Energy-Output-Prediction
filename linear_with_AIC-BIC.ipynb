{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09a72779-86eb-445c-8eb3-bc5e4d937cc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Location1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 123\u001b[0m\n\u001b[0;32m    120\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Load and preprocess data\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m X, y \u001b[38;5;241m=\u001b[39m load_and_preprocess_data(filepath)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Remove outliers\u001b[39;00m\n\u001b[0;32m    126\u001b[0m X_clean, y_clean, outliers_count \u001b[38;5;241m=\u001b[39m remove_outliers(X, y)\n",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m, in \u001b[0;36mload_and_preprocess_data\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_preprocess_data\u001b[39m(filepath):\n\u001b[1;32m---> 13\u001b[0m     loc1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(filepath)\n\u001b[0;32m     14\u001b[0m     loc1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(loc1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     15\u001b[0m     loc1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m loc1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Location1.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore \n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(filepath):\n",
    "    loc1 = pd.read_csv(filepath)\n",
    "    loc1['Time'] = pd.to_datetime(loc1['Time'])\n",
    "    loc1['Year'] = loc1['Time'].dt.year\n",
    "    loc1['Month'] = loc1['Time'].dt.month\n",
    "    features = ['Year', 'Month', 'temperature_2m', 'relativehumidity_2m', \n",
    "                'dewpoint_2m', 'windspeed_10m', 'windspeed_100m', \n",
    "                'winddirection_10m', 'winddirection_100m', 'windgusts_10m']\n",
    "    X = loc1[features]\n",
    "    y = loc1['Power']\n",
    "    return X, y\n",
    "\n",
    "# Function to remove outliers\n",
    "def remove_outliers(X, y, threshold=3.0):\n",
    "    features_to_check = X.columns.difference(['Year', 'Month'])\n",
    "    z_scores = np.abs(X[features_to_check].apply(zscore))\n",
    "    mask = (z_scores < threshold).all(axis=1)\n",
    "    \n",
    "    outliers_removed = {feature: np.sum(~mask & (z_scores[feature] >= threshold)) for feature in features_to_check}\n",
    "    \n",
    "    X_clean = X[mask]\n",
    "    y_clean = y[mask]\n",
    "    \n",
    "    return X_clean, y_clean, outliers_removed\n",
    "\n",
    "# Function to calculate adjusted R-squared\n",
    "def adjusted_r2(r2, n, p):\n",
    "    return 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "# Function to train and evaluate linear regression model with AIC/BIC\n",
    "def train_and_evaluate_linear_regression(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit model with statsmodels for AIC/BIC\n",
    "    X_train_sm = sm.add_constant(X_train)\n",
    "    X_test_sm = sm.add_constant(X_test)\n",
    "    model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
    "    \n",
    "    y_pred = model_sm.predict(X_test_sm)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    adj_r2 = adjusted_r2(r2, X_test.shape[0], X_test.shape[1])\n",
    "    aic = model_sm.aic\n",
    "    bic = model_sm.bic\n",
    "    \n",
    "    print('R^2:', r2)\n",
    "    print('Adjusted R^2:', adj_r2)\n",
    "    print('MSE:', mse)\n",
    "    print('RMSE:', rmse)\n",
    "    print('MAE:', mae)\n",
    "    print('AIC:', aic)\n",
    "    print('BIC:', bic)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, y_pred\n",
    "\n",
    "# Function for K-Fold Cross-Validation\n",
    "def kfold_cross_validation(X, y, model):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    results = {'MSE': [], 'RMSE': [], 'MAE': [], 'R^2': [], 'Adj R^2': [], 'AIC': [], 'BIC': []}\n",
    "    y_pred_all = []\n",
    "    y_test_all = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Fit model with statsmodels for AIC/BIC\n",
    "        X_train_sm = sm.add_constant(X_train)\n",
    "        X_test_sm = sm.add_constant(X_test)\n",
    "        model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
    "        \n",
    "        y_pred = model_sm.predict(X_test_sm)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        adj_r2 = adjusted_r2(r2, X_test.shape[0], X_test.shape[1])\n",
    "        aic = model_sm.aic\n",
    "        bic = model_sm.bic\n",
    "        \n",
    "        results['MSE'].append(mse)\n",
    "        results['RMSE'].append(rmse)\n",
    "        results['MAE'].append(mae)\n",
    "        results['R^2'].append(r2)\n",
    "        results['Adj R^2'].append(adj_r2)\n",
    "        results['AIC'].append(aic)\n",
    "        results['BIC'].append(bic)\n",
    "        \n",
    "        y_pred_all.extend(y_pred)\n",
    "        y_test_all.extend(y_test)\n",
    "    \n",
    "    avg_results = {metric: np.mean(values) for metric, values in results.items()}\n",
    "    std_results = {metric: np.std(values) for metric, values in results.items()}\n",
    "    \n",
    "    print(\"\\nCross-Validation Results (Mean ± Std):\")\n",
    "    for metric, avg_value in avg_results.items():\n",
    "        print(f\"{metric}: {avg_value:.4f} ± {std_results[metric]:.4f}\")\n",
    "    \n",
    "    return np.array(y_pred_all), np.array(y_test_all)\n",
    "\n",
    "# Main script execution\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = 'Location1.csv'\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    X, y = load_and_preprocess_data(filepath)\n",
    "    \n",
    "    # Remove outliers\n",
    "    X_clean, y_clean, outliers_count = remove_outliers(X, y)\n",
    "    print(\"Number of outliers removed from each variable:\")\n",
    "    for feature, count in outliers_count.items():\n",
    "        print(f\"{feature}: {count} outliers\")\n",
    "    \n",
    "    # Train and evaluate Linear Regression model\n",
    "    X_train, X_test, y_train, y_test, y_pred = train_and_evaluate_linear_regression(X_clean, y_clean)\n",
    "    \n",
    "    # K-Fold Cross-Validation\n",
    "    y_pred_all, y_test_all = kfold_cross_validation(X_clean, y_clean, LinearRegression())\n",
    "\n",
    "    # Manually plot predictions (if needed, else remove this line)\n",
    "    # plot_predictions(y_test_all, y_pred_all)\n",
    "    \n",
    "    # Define features with high correlation to Power\n",
    "    features_high_corr = ['windspeed_10m', 'windspeed_100m', 'windgusts_10m']\n",
    "    X_high_corr = X_clean[features_high_corr]\n",
    "    y_high_corr = y_clean\n",
    "\n",
    "    # Scale and train Ridge model\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled_high_corr = scaler.fit_transform(X_high_corr)\n",
    "    X_train_high_corr, X_test_high_corr, y_train_high_corr, y_test_high_corr = train_test_split(X_scaled_high_corr, y_high_corr, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model_high_corr = sm.OLS(y_train_high_corr, sm.add_constant(X_train_high_corr)).fit()\n",
    "    \n",
    "    y_pred_high_corr = model_high_corr.predict(sm.add_constant(X_test_high_corr))\n",
    "    r_square_high_corr = r2_score(y_test_high_corr, y_pred_high_corr)\n",
    "    mse_high_corr = mean_squared_error(y_test_high_corr, y_pred_high_corr)\n",
    "    rmse_high_corr = np.sqrt(mse_high_corr)\n",
    "    mae_high_corr = mean_absolute_error(y_test_high_corr, y_pred_high_corr)\n",
    "    adj_r2_high_corr = adjusted_r2(r_square_high_corr, X_test_high_corr.shape[0], X_test_high_corr.shape[1])\n",
    "    aic_high_corr = model_high_corr.aic\n",
    "    bic_high_corr = model_high_corr.bic\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nResults using highly correlated features:\")\n",
    "    print('R^2:', r_square_high_corr)\n",
    "    print('Adjusted R^2:', adj_r2_high_corr)\n",
    "    print('MSE:', mse_high_corr)\n",
    "    print('RMSE:', rmse_high_corr)\n",
    "    print('MAE:', mae_high_corr)\n",
    "    print('AIC:', aic_high_corr)\n",
    "    print('BIC:', bic_high_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ed3fe-7d29-4853-b4b2-4ba7c06a1439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
